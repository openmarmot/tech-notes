{
  "$schema": "https://opencode.ai/config.json",
  "provider": {
    "llama.cpp": {
      "npm": "@ai-sdk/openai-compatible",
      "name": "llama-server (local)",
      "options": {
        "baseURL": "http://10.12.0.57:8080/v1"
      },
      "models": {
        "unsloth/GLM-4.7-Flash-GGUF:UD-Q8_K_XL": {
          "name": "GLM-4.7-Flash (local)",
          "limit": {
            "context": 202752,
            "input": 202752,
            "output": 32768
          },
          "modalities": {
            "input": ["text"],
            "output": ["text"]
          },
          "cost": {
            "input": 0,
            "output": 0
          }
        }
      }
    }
  },
  "model": "llama.cpp/GLM-4.7-Flash"
}